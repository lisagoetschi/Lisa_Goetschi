{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eedc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"add_key\"\n",
    "consumer_secret = \"add_key\"\n",
    "access_key = \"add_key\"\n",
    "access_secret = \"add_key\"\n",
    "bearer_token = \"add_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-28T00:00:00Z',\n",
    "                                 end_time = '2022-11-30T00:00:00Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-08-24T08:23:52Z',\n",
    "                                 end_time = '2022-11-30T00:00:00Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-09-22T06:14:34Z',\n",
    "                                 end_time = '2022-11-30T00:00:00Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce841f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(raw_tweets)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0331692",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets2 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-28T00:00:00Z',\n",
    "                                 end_time = '2022-08-24T08:23:52Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets2.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets3 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-28T00:00:00Z',\n",
    "                                 end_time = '2022-06-15T20:53:28Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets3.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets4 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-28T00:00:00Z',\n",
    "                                 end_time = '2022-03-04T05:46:41Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets4.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c988c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets5 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-24T23:59:59Z',\n",
    "                                 end_time = '2022-03-01T08:36:47Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets5.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3829d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13011f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = []\n",
    "user_dict2 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets2:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result2.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df2 = pd.DataFrame(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830160df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('uk_tag4.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd999ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = []\n",
    "user_dict3 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets3:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result3.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df3 = pd.DataFrame(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('uk_tag5.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aae778",
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = []\n",
    "user_dict4 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets4:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result4.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df4 = pd.DataFrame(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('uk_tag6.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc361b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = []\n",
    "user_dict5 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets5:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result5.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df5 = pd.DataFrame(result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933201ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv('uk_tag7.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b03416",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets6 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-02-24T00:00:00Z',\n",
    "                                 end_time = '2022-02-25T00:00:58Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets6.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result6 = []\n",
    "user_dict6 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets6:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result6.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df6 = pd.DataFrame(result6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('uk_tag8.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets7 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-08-24T08:23:16Z',\n",
    "                                 end_time = '2022-09-22T06:14:34Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets7.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result7 = []\n",
    "user_dict7 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets7:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result7.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df7 = pd.DataFrame(result7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02476b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.to_csv('uk_tag2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets8 = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '\"ukraine krieg\" -is:retweet lang:de',\n",
    "                                 tweet_fields = ['created_at', 'geo', 'text'],\n",
    "                                 start_time = '2022-11-29T23:57:32Z',\n",
    "                                 end_time = '2022-11-30T23:59:59Z'\n",
    "                                  ):\n",
    "    time.sleep(1)\n",
    "    raw_tweets8.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result8 = []\n",
    "user_dict8 = {}\n",
    "# Loop through each response object\n",
    "for response in raw_tweets8:\n",
    "    for tweet in response.data:\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result8.append({\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'geo': tweet.geo\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df8 = pd.DataFrame(result8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.to_csv('uk_tag1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added from differerent notebook the example preparation and analysis of the first week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import germansentiment \n",
    "from nltk.probability import FreqDist\n",
    "from textblob_de import TextBlobDE\n",
    "import csv\n",
    "import string \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from textblob_de import TextBlobDE as TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/lisa/Final_Project_geopolitcs/first_week.csv', 'r') as csv_datei:\n",
    "    reader = csv.reader(csv_datei, delimiter=',')\n",
    "    text = csv_datei.read()\n",
    "    token_text = sent_tokenize(text)\n",
    "    words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_words = []\n",
    "for w in words: lowercase_words.append(w.lower()) \n",
    "print(len(lowercase_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
    "    for ele in string:  \n",
    "        if ele in punc:  \n",
    "            string = string.replace(ele, \"\") \n",
    "    return string\n",
    " \n",
    "lowercase_words_clean = [remove_punc(i) for i in lowercase_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1863151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_words = []\n",
    "\n",
    "for word in lowercase_words_clean:\n",
    "    if word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    elif word.startswith('@'):\n",
    "        word = '@user'\n",
    "    elif word: \n",
    "        word = word\n",
    "        tweet_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b70c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabcfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stopwords = [\"ukraine\", \"ukraine-krieg\", \"mehr\", \"-\", \"via\", \"+++\", \"ukrainekrieg\", \"krieg\", \"tonline\", \"@user\", \"http\"]\n",
    "print(other_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe886105",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_withoutstop = []\n",
    "for word in tweet_words :\n",
    "    if word not in stopwords:\n",
    "        words_withoutstop.append(word)\n",
    "\n",
    "fdist = FreqDist(words_withoutstop)\n",
    "fdist.plot(10)\n",
    "\n",
    "print(len(words), len(words_withoutstop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_withoutstop2 = []\n",
    "for word in words_withoutstop:\n",
    "    if word not in other_stopwords:\n",
    "        words_withoutstop2.append(word)\n",
    "fdist2 = FreqDist(words_withoutstop2)\n",
    "fdist2.plot(10)\n",
    "\n",
    "\n",
    "print(len(words_withoutstop), len(words_withoutstop2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aced20",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_firstweek = ''\n",
    "for x in words_withoutstop2:\n",
    "    string_firstweek += ' ' + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(scale=3,\n",
    "                colormap='Paired',\n",
    "                background_color='white')\n",
    "wc.generate(string_firstweek)\n",
    "\n",
    "plt.imshow(wc)\n",
    "wc.to_file('wordcloud_firstweek.png')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(string_firstweek)\n",
    "\n",
    "print(blob.sentiment)\n",
    "\n",
    "sentiment_mw = blob.sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
